{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "MO7LdeFyYJvV"
      },
      "outputs": [],
      "source": [
        "!pip install rasterio tifffile numpy opencv-python scikit-learn tqdm -q\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rasterio\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tjy7xSdcekB",
        "outputId": "bfd811d1-ede0-4517-fbd1-809b495b4beb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rasterio\n",
            "  Downloading rasterio-1.4.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.1 kB)\n",
            "Collecting affine (from rasterio)\n",
            "  Downloading affine-2.4.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.12/dist-packages (from rasterio) (25.4.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from rasterio) (2025.10.5)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.12/dist-packages (from rasterio) (8.3.0)\n",
            "Collecting cligj>=0.5 (from rasterio)\n",
            "  Downloading cligj-0.7.2-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.12/dist-packages (from rasterio) (1.26.4)\n",
            "Collecting click-plugins (from rasterio)\n",
            "  Downloading click_plugins-1.1.1.2-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from rasterio) (3.2.5)\n",
            "Downloading rasterio-1.4.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (22.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.3/22.3 MB\u001b[0m \u001b[31m113.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cligj-0.7.2-py3-none-any.whl (7.1 kB)\n",
            "Downloading affine-2.4.0-py3-none-any.whl (15 kB)\n",
            "Downloading click_plugins-1.1.1.2-py2.py3-none-any.whl (11 kB)\n",
            "Installing collected packages: cligj, click-plugins, affine, rasterio\n",
            "Successfully installed affine-2.4.0 click-plugins-1.1.1.2 cligj-0.7.2 rasterio-1.4.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import rasterio\n",
        "\n",
        "path = '/content/patches/mask/Perungudi_Annotation_Mask_2023 (1).tif'\n",
        "\n",
        "try:\n",
        "    with rasterio.open(path) as src:\n",
        "        print(\"✅ File opened successfully\")\n",
        "        print(\"Driver:\", src.driver)\n",
        "        print(\"Width, Height:\", src.width, src.height)\n",
        "        print(\"Band count:\", src.count)\n",
        "        print(\"Data type:\", src.dtypes)\n",
        "        print(\"NoData values:\", src.nodatavals)\n",
        "        print(\"CRS:\", src.crs)\n",
        "except Exception as e:\n",
        "    print(\"❌ Error opening file:\", e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvkILxrpZO8H",
        "outputId": "7c5fe56e-6c46-430c-dccf-c3d83cc8378d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ File opened successfully\n",
            "Driver: GTiff\n",
            "Width, Height: 335 224\n",
            "Band count: 1\n",
            "Data type: ('uint8',)\n",
            "NoData values: (None,)\n",
            "CRS: EPSG:4326\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3e289bed"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import rasterio\n",
        "from rasterio.windows import Window\n",
        "from tifffile import imread\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Update with your actual paths\n",
        "sat_image_path = \"/content/patches/image/Perungudi_Sentinel2_Composite_2023.tif\"   # Sentinel image\n",
        "mask_image_path = \"/content/patches/mask/Perungudi_Annotation_Mask_2023.tif\"      # Mask (if available)\n"
      ],
      "metadata": {
        "id": "-lRFBznfbzLZ"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_tif(path):\n",
        "    \"\"\"Safely read GeoTIFF files using rasterio (fallback to tifffile).\"\"\"\n",
        "    try:\n",
        "        with rasterio.open(path) as src:\n",
        "            arr = src.read()  # (bands, H, W)\n",
        "            arr = np.moveaxis(arr, 0, -1)  # → (H, W, bands)\n",
        "        return arr\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ rasterio failed on {path}, retrying with tifffile:\", e)\n",
        "        try:\n",
        "            arr = imread(path)\n",
        "            if arr.ndim == 2:\n",
        "                arr = np.expand_dims(arr, axis=-1)\n",
        "            return arr\n",
        "        except Exception as e2:\n",
        "            raise RuntimeError(f\"❌ Could not read {path}: {e2}\")\n"
      ],
      "metadata": {
        "id": "UOIpP5GRZO1M"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import rasterio\n",
        "\n",
        "def safe_read_tif(path):\n",
        "    \"\"\"Safely read the GeoTIFF and ignore corrupted tiles.\"\"\"\n",
        "    try:\n",
        "        with rasterio.open(path) as src:\n",
        "            # Read the image and mask invalid (corrupted) data automatically\n",
        "            arr = src.read(masked=True)\n",
        "            arr = np.moveaxis(arr, 0, -1)  # (H, W, bands)\n",
        "            print(\"✅ Read successful:\", arr.shape)\n",
        "            return arr\n",
        "    except Exception as e:\n",
        "        print(\"❌ Error reading:\", e)\n",
        "        return None\n",
        "\n",
        "# Test reading your image (replace with correct path)\n",
        "sat_img = safe_read_tif(\"/content/patches/image/Perungudi_Sentinel2_Composite_2023.tif\")\n",
        "\n",
        "# Check if the image was successfully read\n",
        "if sat_img is not None:\n",
        "    print(\"✅ Image read successfully:\", sat_img.shape)\n",
        "else:\n",
        "    print(\"❌ Image read failed.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndyhzYFColI-",
        "outputId": "7070b3f8-dda6-4f49-ec72-8308ad1a0dc6"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Read successful: (224, 335, 26)\n",
            "✅ Image read successfully: (224, 335, 26)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize each band to [0,1] as usual\n",
        "if sat_img is not None:\n",
        "    sat_img = sat_img.astype(np.float32)\n",
        "    for i in range(sat_img.shape[-1]):\n",
        "        band = sat_img[..., i]\n",
        "        min_, max_ = np.min(band), np.max(band)\n",
        "        sat_img[..., i] = (band - min_) / (max_ - min_ + 1e-6)\n",
        "    print(\"✅ Normalization complete.\")\n",
        "else:\n",
        "    print(\"❌ Image is empty. Cannot proceed.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4UaqwzxBomJd",
        "outputId": "4d3383b9-751c-46ea-bd69-4dda5720826b"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Normalization complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PATCH_SIZE = 128\n",
        "image_patches = []\n",
        "\n",
        "# Generate patches from the valid data\n",
        "h, w = sat_img.shape[:2]\n",
        "for i in range(0, h - PATCH_SIZE, PATCH_SIZE):\n",
        "    for j in range(0, w - PATCH_SIZE, PATCH_SIZE):\n",
        "        img_patch = sat_img[i:i+PATCH_SIZE, j:j+PATCH_SIZE]\n",
        "        if img_patch.shape[:2] == (PATCH_SIZE, PATCH_SIZE):\n",
        "            image_patches.append(img_patch)\n",
        "\n",
        "image_patches = np.array(image_patches)\n",
        "print(\"✅ Generated patches:\", image_patches.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62SbI8gqomGu",
        "outputId": "9ca649c2-be6f-4dc7-d93c-4c40979b7f2c"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Generated patches: (2, 128, 128, 26)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow keras numpy tqdm -q\n"
      ],
      "metadata": {
        "id": "wWkjOt57ra1B"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Conv2DTranspose, concatenate, Dropout, BatchNormalization\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications import InceptionResNetV2\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "bitDDWDYomDR"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import (\n",
        "    Conv2D, Conv2DTranspose, Dropout, BatchNormalization,\n",
        "    concatenate, Input\n",
        ")\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications import InceptionResNetV2\n",
        "\n",
        "\n",
        "def align_and_concat(decoder_tensor, encoder_tensor):\n",
        "    \"\"\"Resize encoder tensor to match decoder tensor before concatenation.\"\"\"\n",
        "    dec_shape = tf.shape(decoder_tensor)\n",
        "    encoder_resized = tf.image.resize(\n",
        "        encoder_tensor,\n",
        "        size=(dec_shape[1], dec_shape[2]),\n",
        "        method='bilinear'\n",
        "    )\n",
        "    return concatenate([decoder_tensor, encoder_resized], axis=-1)\n",
        "\n",
        "\n",
        "def irunet(input_shape=(256, 256, 3), num_classes=3):\n",
        "    # Encoder: InceptionResNetV2 pretrained on ImageNet\n",
        "    base_model = InceptionResNetV2(include_top=False, weights='imagenet', input_shape=input_shape)\n",
        "\n",
        "    # Encoder feature blocks for skip connections - Using identified layer names from cell bb41bcd1\n",
        "    # Based on the output of cell bb41bcd1, selecting layers that seem appropriate for skip connections\n",
        "    # based on their position in the network and typical UNet architecture.\n",
        "    # These names might need adjustment based on the specific InceptionResNetV2 implementation.\n",
        "    skips = [\n",
        "        base_model.get_layer('activation_611').output,  # High resolution (after initial conv)\n",
        "        base_model.get_layer('activation_613').output,  # Mid-high resolution (after first max pooling)\n",
        "        base_model.get_layer('activation_615').output,  # Mid resolution (after second max pooling)\n",
        "        base_model.get_layer('activation_681').output,  # Low resolution (before mixed_7a)\n",
        "        base_model.get_layer('activation_771').output  # Deepest (before block8_1)\n",
        "    ]\n",
        "\n",
        "    enc0, enc1, enc2, enc3, enc4 = skips\n",
        "\n",
        "\n",
        "    # Bridge Block (used as bottleneck, adapted from UNet style)\n",
        "    bridge = Conv2D(256, (3, 3), activation='relu', padding='same')(enc4)\n",
        "    bridge = Dropout(0.5)(bridge)\n",
        "    bridge = Conv2D(256, (3, 3), activation='relu', padding='same')(bridge)\n",
        "\n",
        "    # Decoder\n",
        "    # Get shapes of skip connections for target_shape in Conv2DTranspose\n",
        "    enc3_shape = tf.shape(enc3)\n",
        "    dec4 = Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same', target_shape=(enc3_shape[0], enc3_shape[1], enc3_shape[2], 256))(bridge)\n",
        "    dec4 = concatenate([dec4, enc3])\n",
        "    dec4 = Conv2D(256, (3, 3), activation='relu', padding='same')(dec4)\n",
        "    dec4 = BatchNormalization()(dec4)\n",
        "    dec4 = Conv2D(256, (3, 3), activation='relu', padding='same')(dec4)\n",
        "    dec4 = BatchNormalization()(dec4)\n",
        "\n",
        "    enc2_shape = tf.shape(enc2)\n",
        "    dec3 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same', target_shape=(enc2_shape[0], enc2_shape[1], enc2_shape[2], 128))(dec4)\n",
        "    dec3 = concatenate([dec3, enc2])\n",
        "    dec3 = Conv2D(128, (3, 3), activation='relu', padding='same')(dec3)\n",
        "    dec3 = BatchNormalization()(dec3)\n",
        "    dec3 = Conv2D(128, (3, 3), activation='relu', padding='same')(dec3)\n",
        "    dec3 = BatchNormalization()(dec3)\n",
        "\n",
        "    enc1_shape = tf.shape(enc1)\n",
        "    dec2 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same', target_shape=(enc1_shape[0], enc1_shape[1], enc1_shape[2], 64))(dec3)\n",
        "    dec2 = concatenate([dec2, enc1])\n",
        "    dec2 = Conv2D(64, (3, 3), activation='relu', padding='same')(dec2)\n",
        "    dec2 = BatchNormalization()(dec2)\n",
        "    dec2 = Conv2D(64, (3, 3), activation='relu', padding='same')(dec2)\n",
        "    dec2 = BatchNormalization()(dec2)\n",
        "\n",
        "    enc0_shape = tf.shape(enc0)\n",
        "    dec1 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same', target_shape=(enc0_shape[0], enc0_shape[1], enc0_shape[2], 32))(dec2)\n",
        "    dec1 = concatenate([dec1, enc0])\n",
        "    dec1 = Conv2D(32, (3, 3), activation='relu', padding='same')(dec1)\n",
        "    dec1 = BatchNormalization()(dec1)\n",
        "    dec1 = Conv2D(32, (3, 3), activation='relu', padding='same')(dec1)\n",
        "    dec1 = BatchNormalization()(dec1)\n",
        "\n",
        "\n",
        "    # Output Block\n",
        "    output = Conv2D(num_classes, (1, 1), activation='softmax', padding='same')(dec1)\n",
        "    model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "B5WbaqALomBG"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (256, 256, 3)\n",
        "num_classes = 3\n",
        "\n",
        "model = irunet(input_shape, num_classes)\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy', tf.keras.metrics.MeanIoU(num_classes=num_classes)]\n",
        ")\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 702
        },
        "id": "X_LpYUHEol_u",
        "outputId": "c5196b20-ef62-4ef1-e344-78d4bc713a39"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "No such layer: activation_611. Existing layers are: ['input_layer_16', 'conv2d_3260', 'batch_normalization_3252', 'activation_3248', 'conv2d_3261', 'batch_normalization_3253', 'activation_3249', 'conv2d_3262', 'batch_normalization_3254', 'activation_3250', 'max_pooling2d_64', 'conv2d_3263', 'batch_normalization_3255', 'activation_3251', 'conv2d_3264', 'batch_normalization_3256', 'activation_3252', 'max_pooling2d_65', 'conv2d_3268', 'batch_normalization_3260', 'activation_3256', 'conv2d_3266', 'conv2d_3269', 'batch_normalization_3258', 'batch_normalization_3261', 'activation_3254', 'activation_3257', 'average_pooling2d_16', 'conv2d_3265', 'conv2d_3267', 'conv2d_3270', 'conv2d_3271', 'batch_normalization_3257', 'batch_normalization_3259', 'batch_normalization_3262', 'batch_normalization_3263', 'activation_3253', 'activation_3255', 'activation_3258', 'activation_3259', 'mixed_5b', 'conv2d_3275', 'batch_normalization_3267', 'activation_3263', 'conv2d_3273', 'conv2d_3276', 'batch_normalization_3265', 'batch_normalization_3268', 'activation_3261', 'activation_3264', 'conv2d_3272', 'conv2d_3274', 'conv2d_3277', 'batch_normalization_3264', 'batch_normalization_3266', 'batch_normalization_3269', 'activation_3260', 'activation_3262', 'activation_3265', 'block35_1_mixed', 'block35_1_conv', 'custom_scale_layer_640', 'block35_1_ac', 'conv2d_3281', 'batch_normalization_3273', 'activation_3269', 'conv2d_3279', 'conv2d_3282', 'batch_normalization_3271', 'batch_normalization_3274', 'activation_3267', 'activation_3270', 'conv2d_3278', 'conv2d_3280', 'conv2d_3283', 'batch_normalization_3270', 'batch_normalization_3272', 'batch_normalization_3275', 'activation_3266', 'activation_3268', 'activation_3271', 'block35_2_mixed', 'block35_2_conv', 'custom_scale_layer_641', 'block35_2_ac', 'conv2d_3287', 'batch_normalization_3279', 'activation_3275', 'conv2d_3285', 'conv2d_3288', 'batch_normalization_3277', 'batch_normalization_3280', 'activation_3273', 'activation_3276', 'conv2d_3284', 'conv2d_3286', 'conv2d_3289', 'batch_normalization_3276', 'batch_normalization_3278', 'batch_normalization_3281', 'activation_3272', 'activation_3274', 'activation_3277', 'block35_3_mixed', 'block35_3_conv', 'custom_scale_layer_642', 'block35_3_ac', 'conv2d_3293', 'batch_normalization_3285', 'activation_3281', 'conv2d_3291', 'conv2d_3294', 'batch_normalization_3283', 'batch_normalization_3286', 'activation_3279', 'activation_3282', 'conv2d_3290', 'conv2d_3292', 'conv2d_3295', 'batch_normalization_3282', 'batch_normalization_3284', 'batch_normalization_3287', 'activation_3278', 'activation_3280', 'activation_3283', 'block35_4_mixed', 'block35_4_conv', 'custom_scale_layer_643', 'block35_4_ac', 'conv2d_3299', 'batch_normalization_3291', 'activation_3287', 'conv2d_3297', 'conv2d_3300', 'batch_normalization_3289', 'batch_normalization_3292', 'activation_3285', 'activation_3288', 'conv2d_3296', 'conv2d_3298', 'conv2d_3301', 'batch_normalization_3288', 'batch_normalization_3290', 'batch_normalization_3293', 'activation_3284', 'activation_3286', 'activation_3289', 'block35_5_mixed', 'block35_5_conv', 'custom_scale_layer_644', 'block35_5_ac', 'conv2d_3305', 'batch_normalization_3297', 'activation_3293', 'conv2d_3303', 'conv2d_3306', 'batch_normalization_3295', 'batch_normalization_3298', 'activation_3291', 'activation_3294', 'conv2d_3302', 'conv2d_3304', 'conv2d_3307', 'batch_normalization_3294', 'batch_normalization_3296', 'batch_normalization_3299', 'activation_3290', 'activation_3292', 'activation_3295', 'block35_6_mixed', 'block35_6_conv', 'custom_scale_layer_645', 'block35_6_ac', 'conv2d_3311', 'batch_normalization_3303', 'activation_3299', 'conv2d_3309', 'conv2d_3312', 'batch_normalization_3301', 'batch_normalization_3304', 'activation_3297', 'activation_3300', 'conv2d_3308', 'conv2d_3310', 'conv2d_3313', 'batch_normalization_3300', 'batch_normalization_3302', 'batch_normalization_3305', 'activation_3296', 'activation_3298', 'activation_3301', 'block35_7_mixed', 'block35_7_conv', 'custom_scale_layer_646', 'block35_7_ac', 'conv2d_3317', 'batch_normalization_3309', 'activation_3305', 'conv2d_3315', 'conv2d_3318', 'batch_normalization_3307', 'batch_normalization_3310', 'activation_3303', 'activation_3306', 'conv2d_3314', 'conv2d_3316', 'conv2d_3319', 'batch_normalization_3306', 'batch_normalization_3308', 'batch_normalization_3311', 'activation_3302', 'activation_3304', 'activation_3307', 'block35_8_mixed', 'block35_8_conv', 'custom_scale_layer_647', 'block35_8_ac', 'conv2d_3323', 'batch_normalization_3315', 'activation_3311', 'conv2d_3321', 'conv2d_3324', 'batch_normalization_3313', 'batch_normalization_3316', 'activation_3309', 'activation_3312', 'conv2d_3320', 'conv2d_3322', 'conv2d_3325', 'batch_normalization_3312', 'batch_normalization_3314', 'batch_normalization_3317', 'activation_3308', 'activation_3310', 'activation_3313', 'block35_9_mixed', 'block35_9_conv', 'custom_scale_layer_648', 'block35_9_ac', 'conv2d_3329', 'batch_normalization_3321', 'activation_3317', 'conv2d_3327', 'conv2d_3330', 'batch_normalization_3319', 'batch_normalization_3322', 'activation_3315', 'activation_3318', 'conv2d_3326', 'conv2d_3328', 'conv2d_3331', 'batch_normalization_3318', 'batch_normalization_3320', 'batch_normalization_3323', 'activation_3314', 'activation_3316', 'activation_3319', 'block35_10_mixed', 'block35_10_conv', 'custom_scale_layer_649', 'block35_10_ac', 'conv2d_3333', 'batch_normalization_3325', 'activation_3321', 'conv2d_3334', 'batch_normalization_3326', 'activation_3322', 'conv2d_3332', 'conv2d_3335', 'batch_normalization_3324', 'batch_normalization_3327', 'activation_3320', 'activation_3323', 'max_pooling2d_66', 'mixed_6a', 'conv2d_3337', 'batch_normalization_3329', 'activation_3325', 'conv2d_3338', 'batch_normalization_3330', 'activation_3326', 'conv2d_3336', 'conv2d_3339', 'batch_normalization_3328', 'batch_normalization_3331', 'activation_3324', 'activation_3327', 'block17_1_mixed', 'block17_1_conv', 'custom_scale_layer_650', 'block17_1_ac', 'conv2d_3341', 'batch_normalization_3333', 'activation_3329', 'conv2d_3342', 'batch_normalization_3334', 'activation_3330', 'conv2d_3340', 'conv2d_3343', 'batch_normalization_3332', 'batch_normalization_3335', 'activation_3328', 'activation_3331', 'block17_2_mixed', 'block17_2_conv', 'custom_scale_layer_651', 'block17_2_ac', 'conv2d_3345', 'batch_normalization_3337', 'activation_3333', 'conv2d_3346', 'batch_normalization_3338', 'activation_3334', 'conv2d_3344', 'conv2d_3347', 'batch_normalization_3336', 'batch_normalization_3339', 'activation_3332', 'activation_3335', 'block17_3_mixed', 'block17_3_conv', 'custom_scale_layer_652', 'block17_3_ac', 'conv2d_3349', 'batch_normalization_3341', 'activation_3337', 'conv2d_3350', 'batch_normalization_3342', 'activation_3338', 'conv2d_3348', 'conv2d_3351', 'batch_normalization_3340', 'batch_normalization_3343', 'activation_3336', 'activation_3339', 'block17_4_mixed', 'block17_4_conv', 'custom_scale_layer_653', 'block17_4_ac', 'conv2d_3353', 'batch_normalization_3345', 'activation_3341', 'conv2d_3354', 'batch_normalization_3346', 'activation_3342', 'conv2d_3352', 'conv2d_3355', 'batch_normalization_3344', 'batch_normalization_3347', 'activation_3340', 'activation_3343', 'block17_5_mixed', 'block17_5_conv', 'custom_scale_layer_654', 'block17_5_ac', 'conv2d_3357', 'batch_normalization_3349', 'activation_3345', 'conv2d_3358', 'batch_normalization_3350', 'activation_3346', 'conv2d_3356', 'conv2d_3359', 'batch_normalization_3348', 'batch_normalization_3351', 'activation_3344', 'activation_3347', 'block17_6_mixed', 'block17_6_conv', 'custom_scale_layer_655', 'block17_6_ac', 'conv2d_3361', 'batch_normalization_3353', 'activation_3349', 'conv2d_3362', 'batch_normalization_3354', 'activation_3350', 'conv2d_3360', 'conv2d_3363', 'batch_normalization_3352', 'batch_normalization_3355', 'activation_3348', 'activation_3351', 'block17_7_mixed', 'block17_7_conv', 'custom_scale_layer_656', 'block17_7_ac', 'conv2d_3365', 'batch_normalization_3357', 'activation_3353', 'conv2d_3366', 'batch_normalization_3358', 'activation_3354', 'conv2d_3364', 'conv2d_3367', 'batch_normalization_3356', 'batch_normalization_3359', 'activation_3352', 'activation_3355', 'block17_8_mixed', 'block17_8_conv', 'custom_scale_layer_657', 'block17_8_ac', 'conv2d_3369', 'batch_normalization_3361', 'activation_3357', 'conv2d_3370', 'batch_normalization_3362', 'activation_3358', 'conv2d_3368', 'conv2d_3371', 'batch_normalization_3360', 'batch_normalization_3363', 'activation_3356', 'activation_3359', 'block17_9_mixed', 'block17_9_conv', 'custom_scale_layer_658', 'block17_9_ac', 'conv2d_3373', 'batch_normalization_3365', 'activation_3361', 'conv2d_3374', 'batch_normalization_3366', 'activation_3362', 'conv2d_3372', 'conv2d_3375', 'batch_normalization_3364', 'batch_normalization_3367', 'activation_3360', 'activation_3363', 'block17_10_mixed', 'block17_10_conv', 'custom_scale_layer_659', 'block17_10_ac', 'conv2d_3377', 'batch_normalization_3369', 'activation_3365', 'conv2d_3378', 'batch_normalization_3370', 'activation_3366', 'conv2d_3376', 'conv2d_3379', 'batch_normalization_3368', 'batch_normalization_3371', 'activation_3364', 'activation_3367', 'block17_11_mixed', 'block17_11_conv', 'custom_scale_layer_660', 'block17_11_ac', 'conv2d_3381', 'batch_normalization_3373', 'activation_3369', 'conv2d_3382', 'batch_normalization_3374', 'activation_3370', 'conv2d_3380', 'conv2d_3383', 'batch_normalization_3372', 'batch_normalization_3375', 'activation_3368', 'activation_3371', 'block17_12_mixed', 'block17_12_conv', 'custom_scale_layer_661', 'block17_12_ac', 'conv2d_3385', 'batch_normalization_3377', 'activation_3373', 'conv2d_3386', 'batch_normalization_3378', 'activation_3374', 'conv2d_3384', 'conv2d_3387', 'batch_normalization_3376', 'batch_normalization_3379', 'activation_3372', 'activation_3375', 'block17_13_mixed', 'block17_13_conv', 'custom_scale_layer_662', 'block17_13_ac', 'conv2d_3389', 'batch_normalization_3381', 'activation_3377', 'conv2d_3390', 'batch_normalization_3382', 'activation_3378', 'conv2d_3388', 'conv2d_3391', 'batch_normalization_3380', 'batch_normalization_3383', 'activation_3376', 'activation_3379', 'block17_14_mixed', 'block17_14_conv', 'custom_scale_layer_663', 'block17_14_ac', 'conv2d_3393', 'batch_normalization_3385', 'activation_3381', 'conv2d_3394', 'batch_normalization_3386', 'activation_3382', 'conv2d_3392', 'conv2d_3395', 'batch_normalization_3384', 'batch_normalization_3387', 'activation_3380', 'activation_3383', 'block17_15_mixed', 'block17_15_conv', 'custom_scale_layer_664', 'block17_15_ac', 'conv2d_3397', 'batch_normalization_3389', 'activation_3385', 'conv2d_3398', 'batch_normalization_3390', 'activation_3386', 'conv2d_3396', 'conv2d_3399', 'batch_normalization_3388', 'batch_normalization_3391', 'activation_3384', 'activation_3387', 'block17_16_mixed', 'block17_16_conv', 'custom_scale_layer_665', 'block17_16_ac', 'conv2d_3401', 'batch_normalization_3393', 'activation_3389', 'conv2d_3402', 'batch_normalization_3394', 'activation_3390', 'conv2d_3400', 'conv2d_3403', 'batch_normalization_3392', 'batch_normalization_3395', 'activation_3388', 'activation_3391', 'block17_17_mixed', 'block17_17_conv', 'custom_scale_layer_666', 'block17_17_ac', 'conv2d_3405', 'batch_normalization_3397', 'activation_3393', 'conv2d_3406', 'batch_normalization_3398', 'activation_3394', 'conv2d_3404', 'conv2d_3407', 'batch_normalization_3396', 'batch_normalization_3399', 'activation_3392', 'activation_3395', 'block17_18_mixed', 'block17_18_conv', 'custom_scale_layer_667', 'block17_18_ac', 'conv2d_3409', 'batch_normalization_3401', 'activation_3397', 'conv2d_3410', 'batch_normalization_3402', 'activation_3398', 'conv2d_3408', 'conv2d_3411', 'batch_normalization_3400', 'batch_normalization_3403', 'activation_3396', 'activation_3399', 'block17_19_mixed', 'block17_19_conv', 'custom_scale_layer_668', 'block17_19_ac', 'conv2d_3413', 'batch_normalization_3405', 'activation_3401', 'conv2d_3414', 'batch_normalization_3406', 'activation_3402', 'conv2d_3412', 'conv2d_3415', 'batch_normalization_3404', 'batch_normalization_3407', 'activation_3400', 'activation_3403', 'block17_20_mixed', 'block17_20_conv', 'custom_scale_layer_669', 'block17_20_ac', 'conv2d_3420', 'batch_normalization_3412', 'activation_3408', 'conv2d_3416', 'conv2d_3418', 'conv2d_3421', 'batch_normalization_3408', 'batch_normalization_3410', 'batch_normalization_3413', 'activation_3404', 'activation_3406', 'activation_3409', 'conv2d_3417', 'conv2d_3419', 'conv2d_3422', 'batch_normalization_3409', 'batch_normalization_3411', 'batch_normalization_3414', 'activation_3405', 'activation_3407', 'activation_3410', 'max_pooling2d_67', 'mixed_7a', 'conv2d_3424', 'batch_normalization_3416', 'activation_3412', 'conv2d_3425', 'batch_normalization_3417', 'activation_3413', 'conv2d_3423', 'conv2d_3426', 'batch_normalization_3415', 'batch_normalization_3418', 'activation_3411', 'activation_3414', 'block8_1_mixed', 'block8_1_conv', 'custom_scale_layer_670', 'block8_1_ac', 'conv2d_3428', 'batch_normalization_3420', 'activation_3416', 'conv2d_3429', 'batch_normalization_3421', 'activation_3417', 'conv2d_3427', 'conv2d_3430', 'batch_normalization_3419', 'batch_normalization_3422', 'activation_3415', 'activation_3418', 'block8_2_mixed', 'block8_2_conv', 'custom_scale_layer_671', 'block8_2_ac', 'conv2d_3432', 'batch_normalization_3424', 'activation_3420', 'conv2d_3433', 'batch_normalization_3425', 'activation_3421', 'conv2d_3431', 'conv2d_3434', 'batch_normalization_3423', 'batch_normalization_3426', 'activation_3419', 'activation_3422', 'block8_3_mixed', 'block8_3_conv', 'custom_scale_layer_672', 'block8_3_ac', 'conv2d_3436', 'batch_normalization_3428', 'activation_3424', 'conv2d_3437', 'batch_normalization_3429', 'activation_3425', 'conv2d_3435', 'conv2d_3438', 'batch_normalization_3427', 'batch_normalization_3430', 'activation_3423', 'activation_3426', 'block8_4_mixed', 'block8_4_conv', 'custom_scale_layer_673', 'block8_4_ac', 'conv2d_3440', 'batch_normalization_3432', 'activation_3428', 'conv2d_3441', 'batch_normalization_3433', 'activation_3429', 'conv2d_3439', 'conv2d_3442', 'batch_normalization_3431', 'batch_normalization_3434', 'activation_3427', 'activation_3430', 'block8_5_mixed', 'block8_5_conv', 'custom_scale_layer_674', 'block8_5_ac', 'conv2d_3444', 'batch_normalization_3436', 'activation_3432', 'conv2d_3445', 'batch_normalization_3437', 'activation_3433', 'conv2d_3443', 'conv2d_3446', 'batch_normalization_3435', 'batch_normalization_3438', 'activation_3431', 'activation_3434', 'block8_6_mixed', 'block8_6_conv', 'custom_scale_layer_675', 'block8_6_ac', 'conv2d_3448', 'batch_normalization_3440', 'activation_3436', 'conv2d_3449', 'batch_normalization_3441', 'activation_3437', 'conv2d_3447', 'conv2d_3450', 'batch_normalization_3439', 'batch_normalization_3442', 'activation_3435', 'activation_3438', 'block8_7_mixed', 'block8_7_conv', 'custom_scale_layer_676', 'block8_7_ac', 'conv2d_3452', 'batch_normalization_3444', 'activation_3440', 'conv2d_3453', 'batch_normalization_3445', 'activation_3441', 'conv2d_3451', 'conv2d_3454', 'batch_normalization_3443', 'batch_normalization_3446', 'activation_3439', 'activation_3442', 'block8_8_mixed', 'block8_8_conv', 'custom_scale_layer_677', 'block8_8_ac', 'conv2d_3456', 'batch_normalization_3448', 'activation_3444', 'conv2d_3457', 'batch_normalization_3449', 'activation_3445', 'conv2d_3455', 'conv2d_3458', 'batch_normalization_3447', 'batch_normalization_3450', 'activation_3443', 'activation_3446', 'block8_9_mixed', 'block8_9_conv', 'custom_scale_layer_678', 'block8_9_ac', 'conv2d_3460', 'batch_normalization_3452', 'activation_3448', 'conv2d_3461', 'batch_normalization_3453', 'activation_3449', 'conv2d_3459', 'conv2d_3462', 'batch_normalization_3451', 'batch_normalization_3454', 'activation_3447', 'activation_3450', 'block8_10_mixed', 'block8_10_conv', 'custom_scale_layer_679', 'conv_7b', 'conv_7b_bn', 'conv_7b_ac'].",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-103974997.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnum_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mirunet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m model.compile(\n\u001b[1;32m      6\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2063646366.py\u001b[0m in \u001b[0;36mirunet\u001b[0;34m(input_shape, num_classes)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m# These names might need adjustment based on the specific InceptionResNetV2 implementation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     skips = [\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'activation_611'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# High resolution (after initial conv)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'activation_613'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Mid-high resolution (after first max pooling)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'activation_615'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Mid resolution (after second max pooling)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/models/model.py\u001b[0m in \u001b[0;36mget_layer\u001b[0;34m(self, name, index)\u001b[0m\n\u001b[1;32m    208\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    211\u001b[0m                 \u001b[0;34mf\"No such layer: {name}. Existing layers are: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m                 \u001b[0;34mf\"{list(layer.name for layer in self.layers)}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: No such layer: activation_611. Existing layers are: ['input_layer_16', 'conv2d_3260', 'batch_normalization_3252', 'activation_3248', 'conv2d_3261', 'batch_normalization_3253', 'activation_3249', 'conv2d_3262', 'batch_normalization_3254', 'activation_3250', 'max_pooling2d_64', 'conv2d_3263', 'batch_normalization_3255', 'activation_3251', 'conv2d_3264', 'batch_normalization_3256', 'activation_3252', 'max_pooling2d_65', 'conv2d_3268', 'batch_normalization_3260', 'activation_3256', 'conv2d_3266', 'conv2d_3269', 'batch_normalization_3258', 'batch_normalization_3261', 'activation_3254', 'activation_3257', 'average_pooling2d_16', 'conv2d_3265', 'conv2d_3267', 'conv2d_3270', 'conv2d_3271', 'batch_normalization_3257', 'batch_normalization_3259', 'batch_normalization_3262', 'batch_normalization_3263', 'activation_3253', 'activation_3255', 'activation_3258', 'activation_3259', 'mixed_5b', 'conv2d_3275', 'batch_normalization_3267', 'activation_3263', 'conv2d_3273', 'conv2d_3276', 'batch_normalization_3265', 'batch_normalization_3268', 'activation_3261', 'activation_3264', 'conv2d_3272', 'conv2d_3274', 'conv2d_3277', 'batch_normalization_3264', 'batch_normalization_3266', 'batch_normalization_3269', 'activation_3260', 'activation_3262', 'activation_3265', 'block35_1_mixed', 'block35_1_conv', 'custom_scale_layer_640', 'block35_1_ac', 'conv2d_3281', 'batch_normalization_3273', 'activation_3269', 'conv2d_3279', 'conv2d_3282', 'batch_normalization_3271', 'batch_norma..."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bb41bcd1",
        "outputId": "82c29bbc-479e-44bb-ffd1-3248cca7362a"
      },
      "source": [
        "# Instantiate the InceptionResNetV2 model with a dummy input shape\n",
        "base_model = tf.keras.applications.InceptionResNetV2(include_top=False, weights='imagenet', input_shape=(256, 256, 3))\n",
        "\n",
        "# Print the names of all layers in the model\n",
        "for layer in base_model.layers:\n",
        "    print(layer.name)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_layer_3\n",
            "conv2d_611\n",
            "batch_normalization_609\n",
            "activation_609\n",
            "conv2d_612\n",
            "batch_normalization_610\n",
            "activation_610\n",
            "conv2d_613\n",
            "batch_normalization_611\n",
            "activation_611\n",
            "max_pooling2d_12\n",
            "conv2d_614\n",
            "batch_normalization_612\n",
            "activation_612\n",
            "conv2d_615\n",
            "batch_normalization_613\n",
            "activation_613\n",
            "max_pooling2d_13\n",
            "conv2d_619\n",
            "batch_normalization_617\n",
            "activation_617\n",
            "conv2d_617\n",
            "conv2d_620\n",
            "batch_normalization_615\n",
            "batch_normalization_618\n",
            "activation_615\n",
            "activation_618\n",
            "average_pooling2d_3\n",
            "conv2d_616\n",
            "conv2d_618\n",
            "conv2d_621\n",
            "conv2d_622\n",
            "batch_normalization_614\n",
            "batch_normalization_616\n",
            "batch_normalization_619\n",
            "batch_normalization_620\n",
            "activation_614\n",
            "activation_616\n",
            "activation_619\n",
            "activation_620\n",
            "mixed_5b\n",
            "conv2d_626\n",
            "batch_normalization_624\n",
            "activation_624\n",
            "conv2d_624\n",
            "conv2d_627\n",
            "batch_normalization_622\n",
            "batch_normalization_625\n",
            "activation_622\n",
            "activation_625\n",
            "conv2d_623\n",
            "conv2d_625\n",
            "conv2d_628\n",
            "batch_normalization_621\n",
            "batch_normalization_623\n",
            "batch_normalization_626\n",
            "activation_621\n",
            "activation_623\n",
            "activation_626\n",
            "block35_1_mixed\n",
            "block35_1_conv\n",
            "custom_scale_layer_120\n",
            "block35_1_ac\n",
            "conv2d_632\n",
            "batch_normalization_630\n",
            "activation_630\n",
            "conv2d_630\n",
            "conv2d_633\n",
            "batch_normalization_628\n",
            "batch_normalization_631\n",
            "activation_628\n",
            "activation_631\n",
            "conv2d_629\n",
            "conv2d_631\n",
            "conv2d_634\n",
            "batch_normalization_627\n",
            "batch_normalization_629\n",
            "batch_normalization_632\n",
            "activation_627\n",
            "activation_629\n",
            "activation_632\n",
            "block35_2_mixed\n",
            "block35_2_conv\n",
            "custom_scale_layer_121\n",
            "block35_2_ac\n",
            "conv2d_638\n",
            "batch_normalization_636\n",
            "activation_636\n",
            "conv2d_636\n",
            "conv2d_639\n",
            "batch_normalization_634\n",
            "batch_normalization_637\n",
            "activation_634\n",
            "activation_637\n",
            "conv2d_635\n",
            "conv2d_637\n",
            "conv2d_640\n",
            "batch_normalization_633\n",
            "batch_normalization_635\n",
            "batch_normalization_638\n",
            "activation_633\n",
            "activation_635\n",
            "activation_638\n",
            "block35_3_mixed\n",
            "block35_3_conv\n",
            "custom_scale_layer_122\n",
            "block35_3_ac\n",
            "conv2d_644\n",
            "batch_normalization_642\n",
            "activation_642\n",
            "conv2d_642\n",
            "conv2d_645\n",
            "batch_normalization_640\n",
            "batch_normalization_643\n",
            "activation_640\n",
            "activation_643\n",
            "conv2d_641\n",
            "conv2d_643\n",
            "conv2d_646\n",
            "batch_normalization_639\n",
            "batch_normalization_641\n",
            "batch_normalization_644\n",
            "activation_639\n",
            "activation_641\n",
            "activation_644\n",
            "block35_4_mixed\n",
            "block35_4_conv\n",
            "custom_scale_layer_123\n",
            "block35_4_ac\n",
            "conv2d_650\n",
            "batch_normalization_648\n",
            "activation_648\n",
            "conv2d_648\n",
            "conv2d_651\n",
            "batch_normalization_646\n",
            "batch_normalization_649\n",
            "activation_646\n",
            "activation_649\n",
            "conv2d_647\n",
            "conv2d_649\n",
            "conv2d_652\n",
            "batch_normalization_645\n",
            "batch_normalization_647\n",
            "batch_normalization_650\n",
            "activation_645\n",
            "activation_647\n",
            "activation_650\n",
            "block35_5_mixed\n",
            "block35_5_conv\n",
            "custom_scale_layer_124\n",
            "block35_5_ac\n",
            "conv2d_656\n",
            "batch_normalization_654\n",
            "activation_654\n",
            "conv2d_654\n",
            "conv2d_657\n",
            "batch_normalization_652\n",
            "batch_normalization_655\n",
            "activation_652\n",
            "activation_655\n",
            "conv2d_653\n",
            "conv2d_655\n",
            "conv2d_658\n",
            "batch_normalization_651\n",
            "batch_normalization_653\n",
            "batch_normalization_656\n",
            "activation_651\n",
            "activation_653\n",
            "activation_656\n",
            "block35_6_mixed\n",
            "block35_6_conv\n",
            "custom_scale_layer_125\n",
            "block35_6_ac\n",
            "conv2d_662\n",
            "batch_normalization_660\n",
            "activation_660\n",
            "conv2d_660\n",
            "conv2d_663\n",
            "batch_normalization_658\n",
            "batch_normalization_661\n",
            "activation_658\n",
            "activation_661\n",
            "conv2d_659\n",
            "conv2d_661\n",
            "conv2d_664\n",
            "batch_normalization_657\n",
            "batch_normalization_659\n",
            "batch_normalization_662\n",
            "activation_657\n",
            "activation_659\n",
            "activation_662\n",
            "block35_7_mixed\n",
            "block35_7_conv\n",
            "custom_scale_layer_126\n",
            "block35_7_ac\n",
            "conv2d_668\n",
            "batch_normalization_666\n",
            "activation_666\n",
            "conv2d_666\n",
            "conv2d_669\n",
            "batch_normalization_664\n",
            "batch_normalization_667\n",
            "activation_664\n",
            "activation_667\n",
            "conv2d_665\n",
            "conv2d_667\n",
            "conv2d_670\n",
            "batch_normalization_663\n",
            "batch_normalization_665\n",
            "batch_normalization_668\n",
            "activation_663\n",
            "activation_665\n",
            "activation_668\n",
            "block35_8_mixed\n",
            "block35_8_conv\n",
            "custom_scale_layer_127\n",
            "block35_8_ac\n",
            "conv2d_674\n",
            "batch_normalization_672\n",
            "activation_672\n",
            "conv2d_672\n",
            "conv2d_675\n",
            "batch_normalization_670\n",
            "batch_normalization_673\n",
            "activation_670\n",
            "activation_673\n",
            "conv2d_671\n",
            "conv2d_673\n",
            "conv2d_676\n",
            "batch_normalization_669\n",
            "batch_normalization_671\n",
            "batch_normalization_674\n",
            "activation_669\n",
            "activation_671\n",
            "activation_674\n",
            "block35_9_mixed\n",
            "block35_9_conv\n",
            "custom_scale_layer_128\n",
            "block35_9_ac\n",
            "conv2d_680\n",
            "batch_normalization_678\n",
            "activation_678\n",
            "conv2d_678\n",
            "conv2d_681\n",
            "batch_normalization_676\n",
            "batch_normalization_679\n",
            "activation_676\n",
            "activation_679\n",
            "conv2d_677\n",
            "conv2d_679\n",
            "conv2d_682\n",
            "batch_normalization_675\n",
            "batch_normalization_677\n",
            "batch_normalization_680\n",
            "activation_675\n",
            "activation_677\n",
            "activation_680\n",
            "block35_10_mixed\n",
            "block35_10_conv\n",
            "custom_scale_layer_129\n",
            "block35_10_ac\n",
            "conv2d_684\n",
            "batch_normalization_682\n",
            "activation_682\n",
            "conv2d_685\n",
            "batch_normalization_683\n",
            "activation_683\n",
            "conv2d_683\n",
            "conv2d_686\n",
            "batch_normalization_681\n",
            "batch_normalization_684\n",
            "activation_681\n",
            "activation_684\n",
            "max_pooling2d_14\n",
            "mixed_6a\n",
            "conv2d_688\n",
            "batch_normalization_686\n",
            "activation_686\n",
            "conv2d_689\n",
            "batch_normalization_687\n",
            "activation_687\n",
            "conv2d_687\n",
            "conv2d_690\n",
            "batch_normalization_685\n",
            "batch_normalization_688\n",
            "activation_685\n",
            "activation_688\n",
            "block17_1_mixed\n",
            "block17_1_conv\n",
            "custom_scale_layer_130\n",
            "block17_1_ac\n",
            "conv2d_692\n",
            "batch_normalization_690\n",
            "activation_690\n",
            "conv2d_693\n",
            "batch_normalization_691\n",
            "activation_691\n",
            "conv2d_691\n",
            "conv2d_694\n",
            "batch_normalization_689\n",
            "batch_normalization_692\n",
            "activation_689\n",
            "activation_692\n",
            "block17_2_mixed\n",
            "block17_2_conv\n",
            "custom_scale_layer_131\n",
            "block17_2_ac\n",
            "conv2d_696\n",
            "batch_normalization_694\n",
            "activation_694\n",
            "conv2d_697\n",
            "batch_normalization_695\n",
            "activation_695\n",
            "conv2d_695\n",
            "conv2d_698\n",
            "batch_normalization_693\n",
            "batch_normalization_696\n",
            "activation_693\n",
            "activation_696\n",
            "block17_3_mixed\n",
            "block17_3_conv\n",
            "custom_scale_layer_132\n",
            "block17_3_ac\n",
            "conv2d_700\n",
            "batch_normalization_698\n",
            "activation_698\n",
            "conv2d_701\n",
            "batch_normalization_699\n",
            "activation_699\n",
            "conv2d_699\n",
            "conv2d_702\n",
            "batch_normalization_697\n",
            "batch_normalization_700\n",
            "activation_697\n",
            "activation_700\n",
            "block17_4_mixed\n",
            "block17_4_conv\n",
            "custom_scale_layer_133\n",
            "block17_4_ac\n",
            "conv2d_704\n",
            "batch_normalization_702\n",
            "activation_702\n",
            "conv2d_705\n",
            "batch_normalization_703\n",
            "activation_703\n",
            "conv2d_703\n",
            "conv2d_706\n",
            "batch_normalization_701\n",
            "batch_normalization_704\n",
            "activation_701\n",
            "activation_704\n",
            "block17_5_mixed\n",
            "block17_5_conv\n",
            "custom_scale_layer_134\n",
            "block17_5_ac\n",
            "conv2d_708\n",
            "batch_normalization_706\n",
            "activation_706\n",
            "conv2d_709\n",
            "batch_normalization_707\n",
            "activation_707\n",
            "conv2d_707\n",
            "conv2d_710\n",
            "batch_normalization_705\n",
            "batch_normalization_708\n",
            "activation_705\n",
            "activation_708\n",
            "block17_6_mixed\n",
            "block17_6_conv\n",
            "custom_scale_layer_135\n",
            "block17_6_ac\n",
            "conv2d_712\n",
            "batch_normalization_710\n",
            "activation_710\n",
            "conv2d_713\n",
            "batch_normalization_711\n",
            "activation_711\n",
            "conv2d_711\n",
            "conv2d_714\n",
            "batch_normalization_709\n",
            "batch_normalization_712\n",
            "activation_709\n",
            "activation_712\n",
            "block17_7_mixed\n",
            "block17_7_conv\n",
            "custom_scale_layer_136\n",
            "block17_7_ac\n",
            "conv2d_716\n",
            "batch_normalization_714\n",
            "activation_714\n",
            "conv2d_717\n",
            "batch_normalization_715\n",
            "activation_715\n",
            "conv2d_715\n",
            "conv2d_718\n",
            "batch_normalization_713\n",
            "batch_normalization_716\n",
            "activation_713\n",
            "activation_716\n",
            "block17_8_mixed\n",
            "block17_8_conv\n",
            "custom_scale_layer_137\n",
            "block17_8_ac\n",
            "conv2d_720\n",
            "batch_normalization_718\n",
            "activation_718\n",
            "conv2d_721\n",
            "batch_normalization_719\n",
            "activation_719\n",
            "conv2d_719\n",
            "conv2d_722\n",
            "batch_normalization_717\n",
            "batch_normalization_720\n",
            "activation_717\n",
            "activation_720\n",
            "block17_9_mixed\n",
            "block17_9_conv\n",
            "custom_scale_layer_138\n",
            "block17_9_ac\n",
            "conv2d_724\n",
            "batch_normalization_722\n",
            "activation_722\n",
            "conv2d_725\n",
            "batch_normalization_723\n",
            "activation_723\n",
            "conv2d_723\n",
            "conv2d_726\n",
            "batch_normalization_721\n",
            "batch_normalization_724\n",
            "activation_721\n",
            "activation_724\n",
            "block17_10_mixed\n",
            "block17_10_conv\n",
            "custom_scale_layer_139\n",
            "block17_10_ac\n",
            "conv2d_728\n",
            "batch_normalization_726\n",
            "activation_726\n",
            "conv2d_729\n",
            "batch_normalization_727\n",
            "activation_727\n",
            "conv2d_727\n",
            "conv2d_730\n",
            "batch_normalization_725\n",
            "batch_normalization_728\n",
            "activation_725\n",
            "activation_728\n",
            "block17_11_mixed\n",
            "block17_11_conv\n",
            "custom_scale_layer_140\n",
            "block17_11_ac\n",
            "conv2d_732\n",
            "batch_normalization_730\n",
            "activation_730\n",
            "conv2d_733\n",
            "batch_normalization_731\n",
            "activation_731\n",
            "conv2d_731\n",
            "conv2d_734\n",
            "batch_normalization_729\n",
            "batch_normalization_732\n",
            "activation_729\n",
            "activation_732\n",
            "block17_12_mixed\n",
            "block17_12_conv\n",
            "custom_scale_layer_141\n",
            "block17_12_ac\n",
            "conv2d_736\n",
            "batch_normalization_734\n",
            "activation_734\n",
            "conv2d_737\n",
            "batch_normalization_735\n",
            "activation_735\n",
            "conv2d_735\n",
            "conv2d_738\n",
            "batch_normalization_733\n",
            "batch_normalization_736\n",
            "activation_733\n",
            "activation_736\n",
            "block17_13_mixed\n",
            "block17_13_conv\n",
            "custom_scale_layer_142\n",
            "block17_13_ac\n",
            "conv2d_740\n",
            "batch_normalization_738\n",
            "activation_738\n",
            "conv2d_741\n",
            "batch_normalization_739\n",
            "activation_739\n",
            "conv2d_739\n",
            "conv2d_742\n",
            "batch_normalization_737\n",
            "batch_normalization_740\n",
            "activation_737\n",
            "activation_740\n",
            "block17_14_mixed\n",
            "block17_14_conv\n",
            "custom_scale_layer_143\n",
            "block17_14_ac\n",
            "conv2d_744\n",
            "batch_normalization_742\n",
            "activation_742\n",
            "conv2d_745\n",
            "batch_normalization_743\n",
            "activation_743\n",
            "conv2d_743\n",
            "conv2d_746\n",
            "batch_normalization_741\n",
            "batch_normalization_744\n",
            "activation_741\n",
            "activation_744\n",
            "block17_15_mixed\n",
            "block17_15_conv\n",
            "custom_scale_layer_144\n",
            "block17_15_ac\n",
            "conv2d_748\n",
            "batch_normalization_746\n",
            "activation_746\n",
            "conv2d_749\n",
            "batch_normalization_747\n",
            "activation_747\n",
            "conv2d_747\n",
            "conv2d_750\n",
            "batch_normalization_745\n",
            "batch_normalization_748\n",
            "activation_745\n",
            "activation_748\n",
            "block17_16_mixed\n",
            "block17_16_conv\n",
            "custom_scale_layer_145\n",
            "block17_16_ac\n",
            "conv2d_752\n",
            "batch_normalization_750\n",
            "activation_750\n",
            "conv2d_753\n",
            "batch_normalization_751\n",
            "activation_751\n",
            "conv2d_751\n",
            "conv2d_754\n",
            "batch_normalization_749\n",
            "batch_normalization_752\n",
            "activation_749\n",
            "activation_752\n",
            "block17_17_mixed\n",
            "block17_17_conv\n",
            "custom_scale_layer_146\n",
            "block17_17_ac\n",
            "conv2d_756\n",
            "batch_normalization_754\n",
            "activation_754\n",
            "conv2d_757\n",
            "batch_normalization_755\n",
            "activation_755\n",
            "conv2d_755\n",
            "conv2d_758\n",
            "batch_normalization_753\n",
            "batch_normalization_756\n",
            "activation_753\n",
            "activation_756\n",
            "block17_18_mixed\n",
            "block17_18_conv\n",
            "custom_scale_layer_147\n",
            "block17_18_ac\n",
            "conv2d_760\n",
            "batch_normalization_758\n",
            "activation_758\n",
            "conv2d_761\n",
            "batch_normalization_759\n",
            "activation_759\n",
            "conv2d_759\n",
            "conv2d_762\n",
            "batch_normalization_757\n",
            "batch_normalization_760\n",
            "activation_757\n",
            "activation_760\n",
            "block17_19_mixed\n",
            "block17_19_conv\n",
            "custom_scale_layer_148\n",
            "block17_19_ac\n",
            "conv2d_764\n",
            "batch_normalization_762\n",
            "activation_762\n",
            "conv2d_765\n",
            "batch_normalization_763\n",
            "activation_763\n",
            "conv2d_763\n",
            "conv2d_766\n",
            "batch_normalization_761\n",
            "batch_normalization_764\n",
            "activation_761\n",
            "activation_764\n",
            "block17_20_mixed\n",
            "block17_20_conv\n",
            "custom_scale_layer_149\n",
            "block17_20_ac\n",
            "conv2d_771\n",
            "batch_normalization_769\n",
            "activation_769\n",
            "conv2d_767\n",
            "conv2d_769\n",
            "conv2d_772\n",
            "batch_normalization_765\n",
            "batch_normalization_767\n",
            "batch_normalization_770\n",
            "activation_765\n",
            "activation_767\n",
            "activation_770\n",
            "conv2d_768\n",
            "conv2d_770\n",
            "conv2d_773\n",
            "batch_normalization_766\n",
            "batch_normalization_768\n",
            "batch_normalization_771\n",
            "activation_766\n",
            "activation_768\n",
            "activation_771\n",
            "max_pooling2d_15\n",
            "mixed_7a\n",
            "conv2d_775\n",
            "batch_normalization_773\n",
            "activation_773\n",
            "conv2d_776\n",
            "batch_normalization_774\n",
            "activation_774\n",
            "conv2d_774\n",
            "conv2d_777\n",
            "batch_normalization_772\n",
            "batch_normalization_775\n",
            "activation_772\n",
            "activation_775\n",
            "block8_1_mixed\n",
            "block8_1_conv\n",
            "custom_scale_layer_150\n",
            "block8_1_ac\n",
            "conv2d_779\n",
            "batch_normalization_777\n",
            "activation_777\n",
            "conv2d_780\n",
            "batch_normalization_778\n",
            "activation_778\n",
            "conv2d_778\n",
            "conv2d_781\n",
            "batch_normalization_776\n",
            "batch_normalization_779\n",
            "activation_776\n",
            "activation_779\n",
            "block8_2_mixed\n",
            "block8_2_conv\n",
            "custom_scale_layer_151\n",
            "block8_2_ac\n",
            "conv2d_783\n",
            "batch_normalization_781\n",
            "activation_781\n",
            "conv2d_784\n",
            "batch_normalization_782\n",
            "activation_782\n",
            "conv2d_782\n",
            "conv2d_785\n",
            "batch_normalization_780\n",
            "batch_normalization_783\n",
            "activation_780\n",
            "activation_783\n",
            "block8_3_mixed\n",
            "block8_3_conv\n",
            "custom_scale_layer_152\n",
            "block8_3_ac\n",
            "conv2d_787\n",
            "batch_normalization_785\n",
            "activation_785\n",
            "conv2d_788\n",
            "batch_normalization_786\n",
            "activation_786\n",
            "conv2d_786\n",
            "conv2d_789\n",
            "batch_normalization_784\n",
            "batch_normalization_787\n",
            "activation_784\n",
            "activation_787\n",
            "block8_4_mixed\n",
            "block8_4_conv\n",
            "custom_scale_layer_153\n",
            "block8_4_ac\n",
            "conv2d_791\n",
            "batch_normalization_789\n",
            "activation_789\n",
            "conv2d_792\n",
            "batch_normalization_790\n",
            "activation_790\n",
            "conv2d_790\n",
            "conv2d_793\n",
            "batch_normalization_788\n",
            "batch_normalization_791\n",
            "activation_788\n",
            "activation_791\n",
            "block8_5_mixed\n",
            "block8_5_conv\n",
            "custom_scale_layer_154\n",
            "block8_5_ac\n",
            "conv2d_795\n",
            "batch_normalization_793\n",
            "activation_793\n",
            "conv2d_796\n",
            "batch_normalization_794\n",
            "activation_794\n",
            "conv2d_794\n",
            "conv2d_797\n",
            "batch_normalization_792\n",
            "batch_normalization_795\n",
            "activation_792\n",
            "activation_795\n",
            "block8_6_mixed\n",
            "block8_6_conv\n",
            "custom_scale_layer_155\n",
            "block8_6_ac\n",
            "conv2d_799\n",
            "batch_normalization_797\n",
            "activation_797\n",
            "conv2d_800\n",
            "batch_normalization_798\n",
            "activation_798\n",
            "conv2d_798\n",
            "conv2d_801\n",
            "batch_normalization_796\n",
            "batch_normalization_799\n",
            "activation_796\n",
            "activation_799\n",
            "block8_7_mixed\n",
            "block8_7_conv\n",
            "custom_scale_layer_156\n",
            "block8_7_ac\n",
            "conv2d_803\n",
            "batch_normalization_801\n",
            "activation_801\n",
            "conv2d_804\n",
            "batch_normalization_802\n",
            "activation_802\n",
            "conv2d_802\n",
            "conv2d_805\n",
            "batch_normalization_800\n",
            "batch_normalization_803\n",
            "activation_800\n",
            "activation_803\n",
            "block8_8_mixed\n",
            "block8_8_conv\n",
            "custom_scale_layer_157\n",
            "block8_8_ac\n",
            "conv2d_807\n",
            "batch_normalization_805\n",
            "activation_805\n",
            "conv2d_808\n",
            "batch_normalization_806\n",
            "activation_806\n",
            "conv2d_806\n",
            "conv2d_809\n",
            "batch_normalization_804\n",
            "batch_normalization_807\n",
            "activation_804\n",
            "activation_807\n",
            "block8_9_mixed\n",
            "block8_9_conv\n",
            "custom_scale_layer_158\n",
            "block8_9_ac\n",
            "conv2d_811\n",
            "batch_normalization_809\n",
            "activation_809\n",
            "conv2d_812\n",
            "batch_normalization_810\n",
            "activation_810\n",
            "conv2d_810\n",
            "conv2d_813\n",
            "batch_normalization_808\n",
            "batch_normalization_811\n",
            "activation_808\n",
            "activation_811\n",
            "block8_10_mixed\n",
            "block8_10_conv\n",
            "custom_scale_layer_159\n",
            "conv_7b\n",
            "conv_7b_bn\n",
            "conv_7b_ac\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Assume you already have your training and validation data in X_train, Y_train, X_val, Y_val\n",
        "# Convert the labels to categorical (one-hot encoding)\n",
        "Y_train_cat = to_categorical(Y_train, num_classes=num_classes)\n",
        "Y_val_cat = to_categorical(Y_val, num_classes=num_classes)\n",
        "\n",
        "# Check the shape of the labels to ensure they are correctly one-hot encoded\n",
        "print(\"Y_train_cat shape:\", Y_train_cat.shape)\n",
        "print(\"Y_val_cat shape:\", Y_val_cat.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "wC43DBtnrp4a",
        "outputId": "44a222d2-1b1b-4d27-8000-a14403cce98d"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'Y_train' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-425600155.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Assume you already have your training and validation data in X_train, Y_train, X_val, Y_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Convert the labels to categorical (one-hot encoding)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mY_train_cat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mY_val_cat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Y_train' is not defined"
          ]
        }
      ]
    }
  ]
}